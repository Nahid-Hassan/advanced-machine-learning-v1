{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3sMq5tZX3FY"
   },
   "source": [
    "### Create Embedding model using Keras Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fWXyS23mX3FY"
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "# define documents\n",
    "Sent = ['Hello, how are you',\n",
    "        'how are you',\n",
    "        'how are you doing',\n",
    "        'I am doing great',\n",
    "        'I am doing good',\n",
    "        'I am good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HCEpAwUXX3FZ"
   },
   "outputs": [],
   "source": [
    "# defining class labels\n",
    "sent_labels = array([1,1,1,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FUyw5yXZX3FZ",
    "outputId": "b71975c5-adb7-4921-d098-917c44c94270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26, 22, 24, 4], [22, 24, 4], [22, 24, 4, 28], [14, 20, 28, 19], [14, 20, 28, 16], [14, 20, 16]]\n"
     ]
    }
   ],
   "source": [
    "# integer encoding of the documents\n",
    "my_vocab_size = 30\n",
    "encoded_sent = [one_hot(i, my_vocab_size) for i in Sent]\n",
    "print(encoded_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bFM8AAE2X3Fa",
    "outputId": "543f66cd-3c7b-48fa-d64e-7a77cdcfde9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 26 22 24  4]\n",
      " [ 0  0 22 24  4]\n",
      " [ 0 22 24  4 28]\n",
      " [ 0 14 20 28 19]\n",
      " [ 0 14 20 28 16]\n",
      " [ 0  0 14 20 16]]\n"
     ]
    }
   ],
   "source": [
    "# padding documents to a max length =5 \n",
    "length = 5\n",
    "padded_sent = pad_sequences(encoded_sent, maxlen=length, padding='pre')\n",
    "print(padded_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AwMY-es7X3Fa"
   },
   "outputs": [],
   "source": [
    "max_length = 5\n",
    "# defining the model\n",
    "mymodel = Sequential()\n",
    "mymodel.add(Embedding(my_vocab_size, 8, input_length=max_length))\n",
    "mymodel.add(Flatten())\n",
    "mymodel.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uvBtHGNOX3Fa"
   },
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "mymodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SY46PGTmX3Fb",
    "outputId": "aaa54371-6d40-4afe-e454-b6deb453f6db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 965us/step - loss: 0.6855 - accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6791 - accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.8333\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6665 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6623 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6603 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6582 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6456 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6435 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6414 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6393 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6285 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6263 - accuracy: 1.0000\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "# fiting  the model\n",
    "mymodel.fit(padded_sent, sent_labels, epochs=30)\n",
    "\n",
    "# evaluate the model\n",
    "modelloss, modelaccuracy = mymodel.evaluate(padded_sent, sent_labels, verbose=0)\n",
    "print('Accuracy: %f' % (modelaccuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Xm8YY7kX3Fc"
   },
   "source": [
    "# The Prediction part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4XAqQpgmX3Fc"
   },
   "outputs": [],
   "source": [
    "mysent_to_predict = ['how are you Suman',\n",
    "        'I am good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vJLea1oaX3Fc",
    "outputId": "23be81c9-a223-4bc9-8927-917c200e9d84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22, 24, 4, 9], [14, 20, 16]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "vocab_size = 30\n",
    "encoded = [one_hot(d, vocab_size) for d in mysent_to_predict]\n",
    "print(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TIILJtbqX3Fd",
    "outputId": "c4a25caa-0bac-4824-dc8c-6213812e4862"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 22 24  4  9]\n",
      " [ 0  0 14 20 16]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 5 words\n",
    "max_length = 5\n",
    "mypadded = pad_sequences(encoded, maxlen=max_length, padding='pre')\n",
    "print(mypadded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "v-bejyviX3Fe",
    "outputId": "7367db48-83e3-457d-a87c-0112fe2df6f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-c8c43006ee67>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.predict_classes(mypadded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCl3ckyTX3Fe"
   },
   "source": [
    "# Option 1 - Using Pre Trained Word2Vec Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "YAF56fS7X3Ff"
   },
   "source": [
    "from gensim.models import KeyedVector   \n",
    "import os \n",
    "os.chdir(\"F:\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BK5VMYxXX3Ff"
   },
   "outputs": [],
   "source": [
    "#Download GoogleNews-vectors-negative300.bin from \n",
    "#https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "KA0mGYHyX3Fg"
   },
   "source": [
    "PreTrainedModel = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "wG_zVS77X3Fg",
    "outputId": "43720e3f-e7cc-4e23-a582-de3f7b248be6"
   },
   "source": [
    "# calculate: (king - man) + woman = ?\n",
    "result = PreTrainedModel.most_similar(\"Data\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Creating Word Embedding Using Gensim.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
